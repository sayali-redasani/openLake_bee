# BEE Movie Chatbot

## Chatbot walkthrough
https://www.loom.com/share/36cbd036c45844b3baf078d648c6d103?sid=d2b2fc3d-0d7d-465a-9800-05b12a937fe1

## ğŸ“ Overview
The **BEE Movie Chatbot** is a Retrieval-Augmented Generation (RAG) and sentiment analysis-based chatbot built using **Langraph**. This agentic chatbot is designed to analyze sentiment, understand queries, and provide responses based on the context of the Bee Movie.

## ğŸ¤– Agents
The chatbot is structured into multiple agents, each handling a specific task:
- **Supervisor Agent**: Manages and orchestrates responses between different agents.
- **Sentiment Analysis Agent**: Analyzes the sentiment of user queries to enhance response relevance.
- **Query Response Agent**: Retrieves and generates responses based on the Bee Movie dataset.

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/sayali-redasani/openLake_bee.git
cd openLake_bee
cd backend
```

### 2ï¸âƒ£ Create a `.env` File
Create a `.env` file in the root directory and add your API keys and other environment variables:
```ini
OPENAI_API_KEY=your_api_key_here
COHERE_API_KEY=your_api_key_here
```

### 3ï¸âƒ£ Install Dependencies
Ensure you have Python installed, then install the required packages:
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Push Data to the Vector Database
Run the following script to populate your vector database with the Bee Movie dataset:
Kindly ingnore this step as the dataset is already pushed to the vector database.
```sh
python vectorDB_push.py
```

### 5ï¸âƒ£ Run the Application
Start the chatbot server:
```sh
python app.py
```
### Docker Image
```sh
docker pull sayli98/openlakebackend:v1
```
#### Usage
```
docker run -d -p 8000:8000 sayli98/openlakebackend:v1
```

### 6ï¸âƒ£ Start the Frontend
For a user-friendly interface, start the frontend (if applicable):
```sh
cd FrontEnd
npm install  # Install frontend dependencies (if applicable)
npm start    # Run the frontend
```
### Docker Image
```sh
docker pull sayli98/openlake:v1
```
#### Usage
```
docker run -d -p 3000:3000 sayli98/openlake:v1
```


---

## ğŸ“Œ Features
âœ… Retrieval-Augmented Generation (RAG) for accurate responses
âœ… Sentiment analysis to enhance user interactions
âœ… Multi-agent architecture for efficient query handling
âœ… Vector database integration for fast and relevant retrieval
âœ… Scalable and modular design

---

## ğŸ› ï¸ Technologies Used
- **Langraph** (for agentic chatbot functionality)
- **Python** (FastAPI or Flask for backend, depending on implementation)
- **MongoDB Atlas** (as a vector database)
- **Pinecone** (as a vector database)
- **OpenAI GPT-4oMini** (for sentiment analysis)
- **React.js** (for frontend, if applicable)

---

## ğŸ“¬ Contributing
Feel free to contribute! Fork the repo, make your changes, and submit a pull request. ğŸš€

---

## ğŸ“ Contact
For any questions or support, reach out to **Sayali Redasani** at `sayaliredasani@gmail.com` or open an issue in the repository.

---

Happy Coding! ğŸğŸ’¬

